{
    "batch_size": 64,
    "best_score": -11.063102420729264,
    "buffer_size": 100000,
    "gamma": 0.95,
    "noise": {
        "exploration_mu": 0.0,
        "exploration_sigma": 0.3,
        "exploration_theta": 0.15
    },
    "reward_function": "    def get_reward(self):\n        \"\"\"Uses current pose of sim to return reward.\"\"\"\n        # 1 - .3 * (abs(self.sim.pose[:3] - self.target_pos)).sum()\n\n        # recompensa pela velocidade do eixo para a decolagem\n        reward = 0.01 * self.sim.v[2]\n\n        # recompensa constante para se manter dentro do quadrante v\u00e1lido\n        reward += 1.\n\n        # penalizar pela instabilidade dos angulos\n        reward -= 0.01 * abs(self.sim.pose[3:]).sum()\n\n        # penalizar pela distancia do eixos x, y, z do target\n        reward -= 0.1 * pow(self.sim.pose[2] - self.target_pos[2], 2)\n\n        reward -= 0.1 * np.sum(abs(self.sim.pose[:2] - self.target_pos[:2]))\n\n        # penalizar pela velocidades dos outros eixos\n        reward -= 0.01 * np.sum(abs(self.sim.v[:2]))\n\n        return reward\n",
    "tau": 0.01
}